---
title: "Fraud Detection"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

a) load data in R
```{r pressure, echo=FALSE}
Frauddata = read.csv("C:/Users/james/Desktop/Ryerson DATA Analytics/Capstone/FraudDetection.csv", header = T)
Frauddata = data.frame(Frauddata)
```


b) Data Exploration
## data preview

```{r}
##change variable 

Frauddata$type = as.character(Frauddata$type)
Frauddata$nameDest = as.character(Frauddata$nameDest)
Frauddata$nameOrig = as.numeric(Frauddata$nameOrig)

head(Frauddata)
str(Frauddata)
```

##check missing value
```{r}
sum(is.na(Frauddata$step))
sum(is.na(Frauddata$type))
sum(is.na(Frauddata$amount))
sum(is.na(Frauddata$nameOrig))
sum(is.na(Frauddata$oldbalanceOrg))
sum(is.na(Frauddata$newbalanceOrig))
sum(is.na(Frauddata$nameDest))
sum(is.na(Frauddata$oldbalanceDest))
sum(is.na(Frauddata$newbalanceDest))
sum(is.na(Frauddata$isFraud))
sum(is.na(Frauddata$isFlaggedFraud))

```

##how many fraudulent/non-fraudulent  transactions
```{r}
length(Frauddata$isFraud[Frauddata$isFraud == 1])
length(Frauddata$isFraud[Frauddata$isFraud == 0])
```
##Check how many distinct items in name
```{r}
length(unique(Frauddata$nameOrig))
length(unique(Frauddata$nameDest))

```

##check how many rows flageed as fraud 

```{r}
length(Frauddata$isFlaggedFraud[Frauddata$isFlaggedFraud == 1])

```


##test normality

```{r}


library(nortest)
ad.test(Frauddata$amount)
ad.test(Frauddata$newbalanceDest)
ad.test(Frauddata$newbalanceOrig)
ad.test(Frauddata$oldbalanceDest)
ad.test(Frauddata$oldbalanceOrg)
##amount,oldbalanceOrg,newbalanceOrig,newbalanceDest,oldbalanceDest are not normally distributed
```

##summary of data 
```{r}
summary(Frauddata)
```

##check outliers
##cook's distance
##multivariate model (ratio is 0.000001729)
```{r}
cooksd = cooks.distance(lm(isFraud~Frauddata$amount+Frauddata$oldbalanceOrg+Frauddata$newbalanceOrig+Frauddata$oldbalanceDest+Frauddata$newbalanceDest, data = Frauddata))

plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")
abline(h = 4*mean(cooksd, na.rm=T), col="red") 
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])
head(Frauddata[influential, ])

```


##Histograms
```{r}
library(ggplot2)
ggplot(Frauddata,aes(x=Frauddata$type, y =Frauddata$isFraud))+geom_bar(stat = "identity", fill = "blue")

length(Frauddata$type[Frauddata$type=="CASH_OUT"])
length(Frauddata$type[Frauddata$type== "TRANSFER"])
unique(Frauddata$type)


ggplot(Frauddata,aes(Frauddata$type))+geom_bar(fill = "red")
 

```


##correlation(spearman non para since numeric variables are not normal)
```{r}
cor(data.frame(Frauddata$amount,Frauddata$oldbalanceOrg,Frauddata$newbalanceOrig, Frauddata$oldbalanceDest,Frauddata$newbalanceDest))
```
c) Data preprocessing


##Randomize the data set 5 times to avoid issue
```{r}
Frauddata = Frauddata[sample(nrow(Frauddata)),]
Frauddata = Frauddata[sample(nrow(Frauddata)),]
Frauddata = Frauddata[sample(nrow(Frauddata)),]
Frauddata = Frauddata[sample(nrow(Frauddata)),]
Frauddata = Frauddata[sample(nrow(Frauddata)),]
head(Frauddata)

```


##Logistic Regression       

```{r}
start_time <- Sys.time()

library(caret)
library(FSelectorRcpp)
library(FSelector)
library(ROSE)
library(dplyr)
library(Metrics)
library(cvAUC)
validateaccruacy=list()
testaccruacy = list()
validaterecall = list()
testrecall = list()
validateprecision = list()
testreprecision = list()
validateF1 = list()
testF1 = list()
MSErrorvalidate = list()
MSErrortest = list()
aucvalidate = list()
auctest = list()

folds = cut(seq(1,nrow(Frauddata)),breaks = 10, labels = F)
for(f in 1:10){
  ##Random Shuffle to avoid overfitting
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  ## spliting data
  
  testIndexes = which(folds == f, arr.ind =T)
  train = Frauddata[-testIndexes,]
  testset = Frauddata[testIndexes,]
  data_train = sample(nrow(train), floor(nrow(train)*0.8))
  trainset = train[data_train,]
  validateset = train[-data_train,]
  ## performing information gain feature selection
  x = information_gain(isFraud ~ ., trainset)
  to_formula(cut_attrs(attrs = x), "Species")
  variable = cut_attrs(attrs = x, k = 0.7)
  variable = c(variable[-1],"isFraud")
  trainset = trainset[variable]
  
  ##Over and under sampling
  trainsetunder = data.frame(ovun.sample(isFraud~.,data = trainset, method = "under", seed =1)$data)
  trainsetboth = data.frame(ovun.sample(isFraud~.,data = trainset, method = "both", seed =1)$data)
  trainsetunder$isFraud = as.factor(trainsetunder$isFraud)
  trainsetboth$isFraud = as.factor(trainsetboth$isFraud)
  
  ##logstic regression 
  

  logisticboth = glm(formula = isFraud~.,family = "binomial",data = trainsetboth)
  probabilities <- logisticboth %>% predict(validateset, type = "response")
  predicted.validate = ifelse(probabilities>0.5,1,0)
  cmvalidate = as.matrix(table(Actual = validateset$isFraud, Predicted =predicted.validate ))
  cmvalidate
  
    n1 = sum(cmvalidate)
   diag1 = diag(cmvalidate)
  accuracyvalidate = sum(diag1) / n1 
  precisionvalidate =  (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[1,2])
   recallvalidate = (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[2,1])
   recallvalidate
    f1validate = 2 * precisionvalidate * recallvalidate / (precisionvalidate + recallvalidate) 
   data.frame(precisionvalidate, recallvalidate, f1validate)
   auc1 = AUC(predicted.validate,validateset$isFraud )
   ##store result
 
     validateaccruacy= append(validateaccruacy,accuracyvalidate)
    validaterecall= append(validaterecall,recallvalidate)
    validateprecision = append(validateprecision,precisionvalidate)
    validateF1= append(validateF1,f1validate)
    MSErrorvalidate = append(MSErrorvalidate,mse(actual = validateset$isFraud, predict = predicted.validate))
    aucvalidate = append(aucvalidate, auc1)
    

  ##
  probabilitiestest <- logisticboth %>% predict(testset, type = "response")
  predicted.test = ifelse(probabilitiestest>0.5,1,0)
  mean(predicted.test == testset$isFraud)
  cm = as.matrix(table(Actual = testset$isFraud, Predicted =predicted.test ))

  n = sum(cm)
   nc = nrow(cm)
   diag = diag(cm)
  accuracy = sum(diag) / n 
  precision = (cm[2,2])/(cm[2,2]+cm[1,2])
   recall = (cm[2,2])/(cm[2,2]+cm[2,1])
  f1 = 2 * precision * recall / (precision + recall) 
   data.frame(precision, recall, f1)
   auc2 = AUC(predicted.test,testset$isFraud )
   
   ##store result
  
   testaccruacy= append(testaccruacy,accuracy)
   testrecall=append(testrecall,recall)
   testreprecision=append(testreprecision,precision)
   testF1= append(testF1,f1)
   MSErrortest = append(MSErrortest,mse(actual = testset$isFraud, predict = predicted.test) )
  auctest = append(auctest, auc2)
       
  }
 end_time <- Sys.time()
end_time - start_time

  ##Validate Result
  mean(as.numeric(validateaccruacy))
  mean(as.numeric(validaterecall))
  mean(as.numeric(validateF1))
  mean(as.numeric(MSErrorvalidate))
  mean(as.numeric(aucvalidate))
  
  matrix(validateaccruacy)
  matrix(validaterecall)
  matrix(validateF1)
  matrix(MSErrorvalidate)
  matrix(aucvalidate)
  
  
  ##test Result
  mean(as.numeric(testaccruacy))
  mean(as.numeric(testrecall))
  mean(as.numeric(testF1))
  mean(as.numeric(MSErrortest))
  mean(as.numeric(auctest))
  
  matrix(testaccruacy)
  matrix(testrecall)
  matrix(testF1)
  matrix(MSErrortest)
  matrix(auctest)
  
```

##stepwise selection
```{r}
start_time <- Sys.time()

library(caret)
library(ROSE)
library(dplyr)
library(MASS)

validateaccruacy=list()
testaccruacy = list()
validaterecall = list()
testrecall = list()
validateprecision = list()
testreprecision = list()
validateF1 = list()
testF1 = list()
MSErrorvalidate = list()
MSErrortest = list()
aucvalidate = list()
auctest = list()

folds = cut(seq(1,nrow(Frauddata)),breaks = 10, labels = F)
for(f in 1:10){
  ##random shuffle avoide overfit
   Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  
  testIndexes = which(folds == f, arr.ind =T)
  ## spliting data
  train = Frauddata[-testIndexes,]
  testset = Frauddata[testIndexes,]
  data_train = sample(nrow(train), floor(nrow(train)*0.8))
  trainset = train[data_train,]
  trainset$isFraud = as.factor(trainset$isFraud)
  validateset = train[-data_train,]
  ## performing forward and backward 
    
   stepMod <- step(lm(isFraud ~ . , data= Frauddatadirection = "both"))
shortlistedVars <- names(unlist(stepMod[[1]])) 
shortlistedVars <- shortlistedVars[!shortlistedVars %in% "(Intercept)"]  
  trainset = trainset[shortlistedVars]


  
  ##Over and under sampling
 
  trainsetboth = data.frame(ovun.sample(isFraud~.,data = trainset, method = "both", seed =1)$data)
  trainsetboth$isFraud = as.factor(trainsetboth$isFraud)
  
  ##logstic regression 
  

  logisticboth = glm(formula = isFraud~.,family = "binomial",data = trainsetboth)
  logisticboth
  probabilities <- logisticboth %>% predict(validateset, type = "response")
  predicted.validate = ifelse(probabilities>0.5,1,0)
  mean(predicted.validate == validateset$isFraud)
  cmvalidate = as.matrix(table(Actual = validateset$isFraud, Predicted =predicted.validate ))

  n1 = sum(cmvalidate)
   nc1 = nrow(cmvalidate)
   diag1 = diag(cmvalidate)
  accuracyvalidate = sum(diag1) / n1 
 precisionvalidate =  (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[1,2])
   recallvalidate = (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[2,1])
  
  f1validate = 2 * precisionvalidate * recallvalidate / (precisionvalidate + recallvalidate) 
   data.frame(precisionvalidate, recallvalidate, f1validate)
   auc1 = AUC(predicted.validate,validateset$isFraud )
   ##store result
 
     validateaccruacy= append(validateaccruacy,accuracyvalidate)
    validaterecall= append(validaterecall,recallvalidate)
    validateprecision = append(validateprecision,precisionvalidate)
    validateF1= append(validateF1,f1validate)
    MSErrorvalidate = append(MSErrorvalidate,mse(actual = validateset$isFraud, predict = predicted.validate))
    aucvalidate = append(aucvalidate, auc1)
 
  ##
  probabilitiestest <- logisticboth %>% predict(testset, type = "response")
  predicted.test = ifelse(probabilitiestest>0.5,1,0)
  mean(predicted.test == testset$isFraud)
  cm = as.matrix(table(Actual = testset$isFraud, Predicted =predicted.test ))
  cm
  n = sum(cm)
   nc = nrow(cm)
   diag = diag(cm)
  accuracy = sum(diag) / n 
   precision = (cm[2,2])/(cm[2,2]+cm[1,2])
   recall = (cm[2,2])/(cm[2,2]+cm[2,1])
  f1 = 2 * precision * recall / (precision + recall) 
   data.frame(precision, recall, f1)
   auc2 = AUC(predicted.test,testset$isFraud )
      ##store result
  
   testaccruacy= append(testaccruacy,accuracy)
   testrecall=append(testrecall,recall)
   testreprecision=append(testreprecision,precision)
   testF1= append(testF1,f1)
   MSErrortest = append(MSErrortest,mse(actual = testset$isFraud, predict = predicted.test) )
    auctest = append(auctest, auc2)
  }
 end_time <- Sys.time()
end_time - start_time

 ##Validate Result
  mean(as.numeric(validateaccruacy))
  mean(as.numeric(validaterecall))
  mean(as.numeric(validateF1))
  mean(as.numeric(MSErrorvalidate))
  mean(as.numeric(aucvalidate))
  
  matrix(validateaccruacy)
  matrix(validaterecall)
  matrix(validateF1)
  matrix(MSErrorvalidate)
  matrix(aucvalidate)
  
  
  ##test Result
  mean(as.numeric(testaccruacy))
  mean(as.numeric(testrecall))
  mean(as.numeric(testF1))
  mean(as.numeric(MSErrortest))
  mean(as.numeric(auctest))
  
  matrix(testaccruacy)
  matrix(testrecall)
  matrix(testF1)
  matrix(MSErrortest)
  matrix(auctest)

```


##Decision tree
```{r}

start_time <- Sys.time()

library(caret)
library(FSelectorRcpp)
library(ROSE)
library(dplyr)
validateaccruacy=list()
testaccruacy = list()
validaterecall = list()
testrecall = list()
validateprecision = list()
testreprecision = list()
validateF1 = list()
testF1 = list()
MSErrorvalidate = list()
MSErrortest = list()
aucvalidate = list()
auctest = list()

folds = cut(seq(1,nrow(Frauddata)),breaks = 10, labels = F)
for(f in 1:10){
    ##random shuffle avoide overfit
   Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  testIndexes = which(folds == f, arr.ind =T)

  ## spliting data
  train = Frauddata[-testIndexes,]
  testset = Frauddata[testIndexes,]
  data_train = sample(nrow(train), floor(nrow(train)*0.8))
  trainset = train[data_train,]
  trainset$isFraud = as.factor(trainset$isFraud)
  validateset = train[-data_train,]
  ## performing forward and backward 

stepMod <- step(lm(isFraud ~ . , data= Frauddatadirection = "both"))
shortlistedVars <- names(unlist(stepMod[[1]])) 
shortlistedVars <- shortlistedVars[!shortlistedVars %in% "(Intercept)"]  
  trainset = trainset[shortlistedVars]
  
  ##Over and under sampling
 
  trainsetboth = data.frame(ovun.sample(isFraud~.,data = trainset, method = "both", seed =1)$data)
  trainsetboth$isFraud = as.factor(trainsetboth$isFraud)
  ##Decision tree
  library(e1071)
  library(rpart)
  fit <- rpart(isFraud~., data = trainsetboth, method = 'class')
  fit
  Vpredict_decisiontree = predict(fit,validateset, type = 'class')
  table_validate = table(Actual = validateset$isFraud, Predicted = Vpredict_decisiontree)
  cmvalidate = as.matrix(table_validate)

  n1 = sum(cmvalidate)
  confusionMatrix(table_validate)
 diag1 = diag(cmvalidate)
  accuracyvalidate = sum(diag1) / n1 
   precisionvalidate =  (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[1,2])
   recallvalidate = (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[2,1])

  f1validate = 2 * precisionvalidate * recallvalidate / (precisionvalidate + recallvalidate) 
   data.frame(precisionvalidate, recallvalidate, f1validate)
   auc1 = AUC(as.numeric(Vpredict_decisiontree),as.numeric(validateset$isFraud))
   ##store result
 
     validateaccruacy= append(validateaccruacy,accuracyvalidate)
    validaterecall= append(validaterecall,recallvalidate)
    validateprecision = append(validateprecision,precisionvalidate)
    validateF1= append(validateF1,f1validate)
    
     MSErrorvalidate = append(MSErrorvalidate,mse(actual = as.numeric(validateset$isFraud), predict =as.numeric( Vpredict_decisiontree)))
    aucvalidate = append(aucvalidate, auc1)
 
    ##
   
   
   
  predict_decisiontree = predict(fit,testset, type = 'class')
  table_test = table(Actual =testset$isFraud,Predicted =predict_decisiontree)
  cm = as.matrix(table_test)
  confusionMatrix(table_test)

  n = sum(cm)
     diag = diag(cm)
  accuracy = sum(diag) / n 
 precision = (cm[2,2])/(cm[2,2]+cm[1,2])
   recall = (cm[2,2])/(cm[2,2]+cm[2,1])
  f1 = 2 * precision * recall / (precision + recall) 
   auc2 = AUC(as.numeric(predict_decisiontree),as.numeric(testset$isFraud) )
       ##store result
  
   testaccruacy= append(testaccruacy,accuracy)
   testrecall=append(testrecall,recall)
   testreprecision=append(testreprecision,precision)
   testF1= append(testF1,f1)
  MSErrortest = append(MSErrortest,mse(actual = as.numeric(testset$isFraud), predict = as.numeric(predict_decisiontree) ))
     auctest = append(auctest, auc2)
 
   }
end_time <- Sys.time()
end_time - start_time
```

```{r}

start_time <- Sys.time()

library(caret)
library(FSelectorRcpp)
library(ROSE)
library(dplyr)
validateaccruacy=list()
testaccruacy = list()
validaterecall = list()
testrecall = list()
validateprecision = list()
testreprecision = list()
validateF1 = list()
testF1 = list()
MSErrorvalidate = list()
MSErrortest = list()
aucvalidate = list()
auctest = list()

folds = cut(seq(1,nrow(Frauddata)),breaks = 10, labels = F)
for(f in 1:10){
    ##random shuffle avoide overfit
   Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  
  testIndexes = which(folds == f, arr.ind =T)

  ## spliting data
  train = Frauddata[-testIndexes,]
  testset = Frauddata[testIndexes,]
  data_train = sample(nrow(train), floor(nrow(train)*0.8))
  trainset = train[data_train,]
  trainset$isFraud = as.factor(trainset$isFraud)
  validateset = train[-data_train,]
  ## performing forward and backward 

  x = information_gain(isFraud ~ ., trainset)
  to_formula(cut_attrs(attrs = x), "Species")
  variable = cut_attrs(attrs = x, k = 0.7)
  variable = c(variable[-1],"isFraud")
  trainset = trainset[variable]
  
  ##Over and under sampling
 
  trainsetboth = data.frame(ovun.sample(isFraud~.,data = trainset, method = "both", seed =1)$data)
  trainsetboth$isFraud = as.factor(trainsetboth$isFraud)
  ##Decision tree
  library(e1071)
  library(rpart)
  fit <- rpart(isFraud~., data = trainsetboth, method = 'class')
  fit
  Vpredict_decisiontree = predict(fit,validateset, type = 'class')
  table_validate = table(Actual = validateset$isFraud, Predicted = Vpredict_decisiontree)
  cmvalidate = as.matrix(table_validate)
  cmvalidate
  confusionMatrix(table_validate)
 diag1 = diag(cmvalidate)
 n1 = sum(cmvalidate)
  accuracyvalidate = sum(diag1) / n1 
  precisionvalidate =  (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[1,2])
   recallvalidate = (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[2,1])
   accuracyvalidate
  f1validate = 2 * precisionvalidate * recallvalidate / (precisionvalidate + recallvalidate) 
   data.frame(precisionvalidate, recallvalidate, f1validate)
   auc1 = AUC(as.numeric(Vpredict_decisiontree),as.numeric(validateset$isFraud) )
  ##store result
 
     validateaccruacy= append(validateaccruacy,accuracyvalidate)
    validaterecall= append(validaterecall,recallvalidate)
    validateprecision = append(validateprecision,precisionvalidate)
    validateF1= append(validateF1,f1validate)
    MSErrorvalidate = append(MSErrorvalidate,mse(actual = as.numeric(validateset$isFraud), predict =as.numeric( Vpredict_decisiontree)))
     aucvalidate = append(aucvalidate, auc1)
      
  S##  
  predict_decisiontree = predict(fit,testset, type = 'class')
  table_test = table(Actual =testset$isFraud,Predicted =predict_decisiontree)
  cm = as.matrix(table_test)
  confusionMatrix(table_test)
  cm
  n = sum(cm)
     diag = diag(cm)
  accuracy = sum(diag) / n 
  precision = (cm[2,2])/(cm[2,2]+cm[1,2])
   recall = (cm[2,2])/(cm[2,2]+cm[2,1])
  f1 = 2 * precision * recall / (precision + recall) 
   data.frame(precision, recall, f1)
   auc2 = AUC(as.numeric(predict_decisiontree),as.numeric(testset$isFraud) )
   ##store result
  
   testaccruacy= append(testaccruacy,accuracy)
   testrecall=append(testrecall,recall)
   testreprecision=append(testreprecision,precision)
   testF1= append(testF1,f1)
    MSErrortest = append(MSErrortest,mse(actual = as.numeric(testset$isFraud), predict = as.numeric(predict_decisiontree) ))
    auctest = append(auctest, auc2)
    
}
end_time <- Sys.time()
end_time - start_time


   
```

##Navie Bayes 
```{r}

start_time <- Sys.time()

library(caret)
library(FSelectorRcpp)
library(ROSE)
library(dplyr)

library(class)
validateaccruacy=list()
testaccruacy = list()
validaterecall = list()
testrecall = list()
validateprecision = list()
testreprecision = list()
validateF1 = list()
testF1 = list()
MSErrorvalidate = list()
MSErrortest = list()
aucvalidate = list()
auctest = list()

folds = cut(seq(1,nrow(Frauddata)),breaks = 10, labels = F)
for(f in 1:10){
    ##random shuffle avoide overfit
   Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  Frauddata = Frauddata[sample(nrow(Frauddata)),]
  
  testIndexes = which(folds == f, arr.ind =T)

  ## spliting data
  train = Frauddata[-testIndexes,]
  testset = Frauddata[testIndexes,]
  data_train = sample(nrow(train), floor(nrow(train)*0.8))
  trainset = train[data_train,]
  trainset$isFraud = as.factor(trainset$isFraud)
  validateset = train[-data_train,]



  ##Over and under sampling
 
  trainsetboth = data.frame(ovun.sample(isFraud~.,data = trainset, method = "both", seed =1)$data)
  trainsetboth$isFraud = as.factor(trainsetboth$isFraud)
 
  
  
  
  #Navie Bayes
  library(e1071)
  NBclassfier=naiveBayes(isFraud~step+amount+type+nameOrig+oldbalanceOrg+newbalanceOrig+oldbalanceDest+newbalanceDest+isFlaggedFraud, data=trainsetboth)
  NBclassfier
  ##
Vpredict_Bayes = predict(NBclassfier,newdata =  validateset, type = "class")
  table_validate = table(Actual = validateset$isFraud, Predicted = Vpredict_Bayes)
  cmvalidate = as.matrix(table_validate)
  confusionMatrix(table_validate)
 diag1 = diag(cmvalidate)
 n1 = sum(cmvalidate)
  accuracyvalidate = sum(diag1) / n1 
 precisionvalidate =  (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[1,2])
   recallvalidate = (cmvalidate[2,2])/(cmvalidate[2,2]+cmvalidate[2,1])
   accuracyvalidate
  f1validate = 2 * precisionvalidate * recallvalidate / (precisionvalidate + recallvalidate) 
   data.frame(precisionvalidate, recallvalidate, f1validate)
   auc1 = AUC(as.numeric(Vpredict_Bayes),as.numeric(validateset$isFraud) )
   ##store result

     validateaccruacy= append(validateaccruacy,accuracyvalidate)
    validaterecall= append(validaterecall,recallvalidate)
    validateprecision = append(validateprecision,precisionvalidate)
    validateF1= append(validateF1,f1validate)
  MSErrorvalidate = append(MSErrorvalidate,mse(actual = as.numeric(validateset$isFraud), predict =as.numeric( Vpredict_Bayes)))
  aucvalidate = append(aucvalidate, auc1)
  mean(as.numeric(aucvalidate))
  
   
  predict_Bayes = predict(NBclassfier,testset, type = "class")
  table_test = table(Actual =testset$isFraud,Predicted =predict_Bayes)
  cm = as.matrix(table_test)
  confusionMatrix(table_test)

  n = sum(cm)
     diag = diag(cm)
  accuracy = sum(diag) / n 
  precision = (cm[2,2])/(cm[2,2]+cm[1,2])
   recall = (cm[2,2])/(cm[2,2]+cm[2,1])
  f1 = 2 * precision * recall / (precision + recall) 
   data.frame(precision, recall, f1)
   auc2 = AUC(as.numeric(predict_Bayes),as.numeric(testset$isFraud) )
     ##store result
  
   testaccruacy= append(testaccruacy,accuracy)
   testrecall=append(testrecall,recall)
   testreprecision=append(testreprecision,precision)
   testF1= append(testF1,f1)
   MSErrortest = append(MSErrortest,mse(actual = as.numeric(testset$isFraud), predict = as.numeric(predict_Bayes) ))
     auctest = append(auctest, auc2)
     
}
end_time <- Sys.time()
end_time - start_time
```